apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: submit_spark_job
  namespace: airflow
spec:
  type: Scala
  mode: cluster
  image: customairflowdocker.azurecr.io/airflow-spark-operator:latest
  imagePullPolicy: Always
  mainClass: dustmq
  mainApplicationFile: "local:///opt/spark/jars/scala-dustmq_2.13-0.1.4-SNAPSHOT.jar"
  sparkVersion: "3.5.2"
  restartPolicy:
    type: OnFailure
  # imagePullSecrets:
  #   - name: acr-secret
  sparkConf:
    "spark.jars.packages": org.apache.spark:spark-sql_2.13:3.5.2,org.apache.spark:spark-core_2.13:3.5.2,org.apache.spark:spark-hive_2.13:3.5.2,com.azure:azure-storage-blob:12.25.0,com.azure:azure-identity:1.11.2,com.microsoft.azure:azure-storage:8.6.6,org.apache.hadoop:hadoop-azure:3.3.6,org.apache.hadoop:hadoop-azure-datalake:3.3.6,org.apache.hadoop:hadoop-common:3.3.6,org.apache.hadoop:hadoop-client:3.3.6,org.apache.hadoop:hadoop-client-api:3.3.6,org.apache.hadoop:hadoop-client-runtime:3.3.6
    "spark.jars.ivy": "/tmp/ivy-cache"
    "spark.jars.repositories": "https://repo1.maven.org/maven2,https://repository.apache.org/snapshots"
    "spark.executor.extraJavaOptions": "-verbose:class"
    # "spark.driver.userClassPathFirst": "true"
    # "spark.executor.userClassPathFirst": "true"
    # "spark.hadoop.security.group.mapping": "org.apache.hadoop.security.ShellBasedUnixGroupsMapping"
    # "spark.hadoop.security.group.mapping.using.native": "false"  

    # "spark.executor.extraJavaOptions": "-Divy.cache.dir=/tmp -Divy.home=/tmp"
    # "spark.driver.extraJavaOptions": "-Divy.cache.dir=/tmp -Divy.home=/tmp"
      
  driver:
    cores: 1
    memory: "500m"
    labels:
      version: 3.5.2
    serviceAccount: spark
    env:
      - name: SPARK_SUBMIT_OPTS
        value: "-Dspark.jars.ivy=/tmp/ivy-cache"
  executor:
    cores: 1
    instances: 2
    memory: "500m"
    env:
      - name: SPARK_SUBMIT_OPTS
        value: "-Dspark.jars.ivy=/tmp/ivy-cache"
